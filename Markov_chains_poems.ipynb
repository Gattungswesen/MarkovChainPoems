{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Markov_chains_poems.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPOkfTkyWa8TsvXN36lkLCd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Gattungswesen/MarkovChainPoems/blob/main/Markov_chains_poems.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R9E-1N_qPMHi"
      },
      "source": [
        "\n",
        "\n",
        "```\n",
        "The learning phase:\n",
        "First, we generate the stochastic matrix using words from our sample text. This\n",
        "is done by iterating through the text one word at a time. For each word, we\n",
        "create a string of the preceding words, the length of which depends on the\n",
        "number of words being considered for the state of the system. We refer to this\n",
        "string as the Key. Using the Key, we look up a second table, which contains the\n",
        "number of times that the key was followed by all other words, and we\n",
        "increment the relevant value by 1.\n",
        "To summarize, after this process we end up with a table of tables of\n",
        "counts. The Key is used in a lookup in the first table, and the word following\n",
        "the Key in the original poetry is used to lookup a count in the second table. The values in the 2nd table contain the actual frequencies with which that word\n",
        "follows the Key.\n",
        "The reason we organized our data this way is that it doesn’t require\n",
        "saving the zero values in the matrix. Since most permutations of words will\n",
        "never appear in the matrix, storing the matrix normally (as a 2-D array) would\n",
        "require huge amounts of memory. By doing it like this, we can infer that any\n",
        "items that didn’t have an entry in the tables must not have occurred in the\n",
        "training data, and therefore have a zero percent chance of happening.```\n",
        "\n",
        "Scraping using Beautifulsoup: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q5cPwGBW01YG"
      },
      "source": [
        "from bs4 import BeautifulSoup as bs\n",
        "import re\n",
        "import requests\n",
        "import json\n",
        "import threading\n",
        "import queue\n",
        "from sys import argv\n",
        "import pickle\n",
        "from collections import defaultdict\n",
        "from math import ceil\n",
        "# from os import exit\n",
        "def getLink():\n",
        "  while True:\n",
        "    time = page = None\n",
        "    try:\n",
        "      time, page = remPgs.get(block=False)\n",
        "    except queue.Empty:\n",
        "     break\n",
        "    print(\"getting pg tbl for pg %i from period %s\"%(page, time))\n",
        "    payload = {'page': str(page), 'preview': '1', 'school-period': time}\n",
        "    r = requests.get(baseURL, params=payload)\n",
        "    if (r.status_code != 200):\n",
        "      print(f\"page {page} failed. status code:{r.status_code}\")\n",
        "      continue\n",
        "    for entry in r.json()['Entries']:\n",
        "        link = entry['link']\n",
        "        links.put((time, link))\n",
        "def getPoems():\n",
        "  while True:\n",
        "    period = url = None\n",
        "    try:\n",
        "      period, url = links.get(block=False)\n",
        "    except Empty:\n",
        "        break\n",
        "    r = requests.get(url)\n",
        "    print(\"loaded page for %s\"%(url))\n",
        "    if (r.status_code != 200):\n",
        "     print(f\"poem lookup failed\")\n",
        "     continue\n",
        "     soup = bs(r.text, 'html.parser')\n",
        "     poem = '\\r'.join([div.text.strip() for div in\n",
        "     soup.find(class_=re.compile('o-poem')).find_all(style=re.compile('text-indent: -1em;'))])\n",
        "     poem = poem.replace('\\n', '')\n",
        "     poem = poem.replace('\\r', '\\n')\n",
        "     poems[period].append(poem)\n",
        "     print(\"added poem in period: %s\"%period)\n",
        "# timePeriods = [('pre-1550', 52), ('1550-1780', 963), ('1781-1900', 1190),('1901-1950', 12984), ('1951-present', 27089)]\n",
        "timePeriods = [('1951-present', 27089)]\n",
        "baseURL = \"https://www.poetryfoundation.org/ajax/poems\"\n",
        "numThreads = 50\n",
        "remPgs = queue.Queue()\n",
        "poemLock = threading.Lock()\n",
        "poems = defaultdict(list)\n",
        "links = queue.Queue()\n",
        "for period, count in timePeriods:\n",
        "  for page in range(ceil(count/20)):\n",
        "    remPgs.put((period, page))\n",
        "    threads = []\n",
        "for _ in range(numThreads):\n",
        "  thread = threading.Thread(target=getLink)\n",
        "  threads.append(thread)\n",
        "  thread.start()\n",
        "for thread in threads:\n",
        "  thread.join()\n",
        "# while not links.empty():\n",
        "# period, url = links.get()\n",
        "# print(period, url)\n",
        "# exit()\n",
        "threads = []\n",
        "for _ in range(numThreads):\n",
        "  thread = threading.Thread(target=getPoems)\n",
        "  threads.append(thread)\n",
        "  thread.start()\n",
        "for thread in threads:\n",
        "  thread.join()\n",
        "  f = open(argv[1], 'wb')\n",
        "  pickle.dump(dict(poems), f)\n",
        "  f.close()\n",
        "# open('./strDmp.txt', 'w').write(str(pages))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1jjpVZ8ZPfcK"
      },
      "source": [
        "\n",
        "\n",
        "```\n",
        "The generation phase:\n",
        "Once the stochastic matrix has been filled in, generating poetry is trivial. First,\n",
        "we randomly select a Key to use as the beginning of the poem. Since this is\n",
        "generated from the matrix, we know that this series of words must have\n",
        "occurred at least once in the training text.\n",
        "Once we have the first word(s), we repeatedly take the last words (again,\n",
        "the number depends on how many words are being included in the state of the\n",
        "system) [2]. This results in a table containing probabilities for the next word.\n",
        "After randomly choosing the next word (based on the relative probabilities in\n",
        "the matrix), the state of the system (corresponding to the last few words) is\n",
        "updated, and the process repeats until the desired poem length is reached. The\n",
        "length of the poem could be programmatically generated by finding the mean\n",
        "and standard deviation of the length of a poem in the sample text, then using\n",
        "that probability distribution to choose the length of each poem. We tried this but found that it just made the process of generating poems less reliable, since sometimes we ended up with very long or very short poems when we really wanted a relatively consistent poem length. As a result, we just manually\n",
        "selected the length of the poems.```\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Generating poems using Markov chains:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PM3TGQ5n1VQZ"
      },
      "source": [
        "import fileinput\n",
        "from collections import Counter, defaultdict\n",
        "import pprint\n",
        "from random import choice, choices\n",
        "from string import ascii_lowercase as ascii_lower\n",
        "import re\n",
        "# The stochastic matrix\n",
        "# I'm using a dictionary data structure to avoid having to allocate a massive matrix that would mostly be full of 0s\n",
        "matrix = defaultdict(Counter)\n",
        "# This is the number of previous words to look at when choosing the next word\n",
        "keyLen = 2\n",
        "# process some training text (for this project, example poetry)\n",
        "def learn(rawTxt):\n",
        " # split up the training text into individual words (and clean up the data a little by removing unwanted character)\n",
        " words = [word.strip().lower() for word in rawTxt.replace('\\n', '').split(' ')]\n",
        " count = Counter()\n",
        " n = len(words)\n",
        " # for each unique group of 'keyLen' adjacent words in the 'words' array\n",
        " # count the relative frequencies of all possible following words\n",
        " for i in range(len(words)-keyLen-1):\n",
        "   key = ' '.join([words[i + j].lower() for j in range(keyLen)])\n",
        "   if (key == '' or key == ' '): continue\n",
        " matrix[key][words[i + keyLen]] += 1\n",
        "# use the stochastic matrix to pick the next word given\n",
        "def pickWord(currentKey = None):\n",
        "  if currentKey == None or currentKey == '': return\n",
        "  choice(list(matrix.keys()))\n",
        "  words, counts = zip(*matrix[currentKey].items())\n",
        "  return choices(words, weights=counts)[0] # this where the actual selection happens\n",
        "# generate an 'nWords' text using the stochastic matrix's probabilities\n",
        "def genText(nWords = 15):\n",
        " sentence = choice(list(matrix.keys())) + ' '\n",
        " for _ in range(nWords):\n",
        "   key = ' '.join(sentence.split()[-keyLen:])\n",
        "   sentence += pickWord(key) + ' '\n",
        "   return sentence\n",
        "def main():\n",
        " global keyLen\n",
        " trainTxt = ''.join([s for s in fileinput.input()])\n",
        " learn(trainTxt) # first we use the training data to generate the matrix\n",
        " for _ in range(3):\n",
        "   resultText = genText(30).strip() # then we generate the text\n",
        "   print(resultText + '\\n\\n')\n",
        " # print(resultText)\n",
        " if __name__==\"__main__\":\n",
        "   main()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}